{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import initial dependencies\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CSVs to DFs\n",
    "feature_csv = \"wine_features.csv\"\n",
    "target_csv = \"wine_targets.csv\"\n",
    "\n",
    "feature_csv_df = pd.read_csv(feature_csv)\n",
    "target_csv_df = pd.read_csv(target_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>country_Australia</th>\n",
       "      <th>points</th>\n",
       "      <th>country_Austria</th>\n",
       "      <th>country_Portugal</th>\n",
       "      <th>country_US</th>\n",
       "      <th>taster_name_Alexander Peartree</th>\n",
       "      <th>taster_name_Matt Kettmann</th>\n",
       "      <th>taster_name_Michael Schachner</th>\n",
       "      <th>taster_name_Paul Gregutt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  country_Australia  points  country_Austria  country_Portugal  \\\n",
       "0   15.0                  0      87                0                 1   \n",
       "1   14.0                  0      87                0                 0   \n",
       "2   13.0                  0      87                0                 0   \n",
       "3   65.0                  0      87                0                 0   \n",
       "4   15.0                  0      87                0                 0   \n",
       "\n",
       "   country_US  taster_name_Alexander Peartree  taster_name_Matt Kettmann  \\\n",
       "0           0                               0                          0   \n",
       "1           1                               0                          0   \n",
       "2           1                               1                          0   \n",
       "3           1                               0                          0   \n",
       "4           0                               0                          0   \n",
       "\n",
       "   taster_name_Michael Schachner  taster_name_Paul Gregutt  \n",
       "0                              0                         0  \n",
       "1                              0                         1  \n",
       "2                              0                         0  \n",
       "3                              0                         1  \n",
       "4                              1                         0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature DF head\n",
    "feature_csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120975, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature DF shape\n",
    "feature_csv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   points\n",
       "0      87\n",
       "1      87\n",
       "2      87\n",
       "3      87\n",
       "4      87"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check target DF head\n",
    "target_csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120975, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check target DF shape\n",
    "target_csv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.  0. 87. ...  0.  0.  0.]\n",
      " [14.  0. 87. ...  0.  0.  1.]\n",
      " [13.  0. 87. ...  0.  0.  0.]\n",
      " ...\n",
      " [30.  0. 90. ...  0.  0.  0.]\n",
      " [32.  0. 90. ...  0.  0.  0.]\n",
      " [21.  0. 90. ...  0.  0.  0.]] [[87]\n",
      " [87]\n",
      " [87]\n",
      " ...\n",
      " [90]\n",
      " [90]\n",
      " [90]]\n"
     ]
    }
   ],
   "source": [
    "# Assign the features and target to X and y abd check assignments\n",
    "raw_feature_data = feature_csv_df.values\n",
    "raw_target_data = target_csv_df.values\n",
    "X = raw_feature_data[:, 0:10]\n",
    "y = raw_target_data.reshape(-1,1)\n",
    "\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT, NORMALIZE, AND ENCODE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and test sets for the features and target\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using the MinMax scaler since we know their values\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "y_scaler = MinMaxScaler().fit(y_train)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPERAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sequential and dense modules fo build my NN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for activation method\n",
    "# def create_base_model(activation='relu'):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='relu', input_dim=6))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=1, activation='linear'))\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create activation model\n",
    "# model = KerasRegressor(build_fn=create_base_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the activation grid search parameters\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "\n",
    "\n",
    "# # Assign the activation grid search parameters, fit, and run the model\n",
    "# param_grid = dict(activation=activation)\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, refit=True, verbose=3)\n",
    "# grid_result = grid.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howar\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   23.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "90731/90731 [==============================] - 12s 136us/step - loss: 171.4343\n"
     ]
    }
   ],
   "source": [
    "# Create the base Keras classifier wrapper for activation method\n",
    "def create_base_model(activation='relu'):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1000, activation='relu', input_dim=10))\n",
    "    model.add(Dense(units=1000, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Create activation model\n",
    "model = KerasRegressor(build_fn=create_base_model, epochs=1, batch_size=88)\n",
    "\n",
    "\n",
    "# Define the activation grid search parameters\n",
    "activation = ['linear']\n",
    "\n",
    "\n",
    "# Assign the activation grid search parameters, fit, and run the model\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, refit=True, verbose=3)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.026754 using {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Print the score and best params for the activation model\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.1252451092613301\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "pred = grid_result.predict(X_test_scaled)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
    "\n",
    "print(f'Final score (RMSE): {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([84.94114 , 86.865585, 91.92523 , 89.93236 , 94.017624, 82.9285  ,\n",
       "       87.93129 , 86.9357  , 85.930756, 87.932495], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.predict(X_test_scaled[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85],\n",
       "       [87],\n",
       "       [92],\n",
       "       [90],\n",
       "       [94],\n",
       "       [83],\n",
       "       [88],\n",
       "       [87],\n",
       "       [86],\n",
       "       [88]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.01568633739388251\n",
      "R-squared (R2 ): 0.9983100108561086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Use our model to predict a value\n",
    "predicted = grid_result.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse = mean_squared_error(y_test, predicted)\n",
    "r2 = r2_score(y_test, predicted)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Training Data Score: {grid_result.score(X_train_scaled, y_train_scaled)}\")\n",
    "# print(f\"Testing Data Score: {grid_result.score(X_test_scaled, y_test_scaled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# kfold = KFold(n_splits=10)\n",
    "# results = cross_val_score(grid_result, X_train_scaled, y_train_scaled, cv=kfold)\n",
    "# print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WINE_Sequential_NN.sav']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the tuned model for future use\n",
    "import joblib\n",
    "filename = 'WINE_Sequential_NN.sav'\n",
    "joblib.dump(grid_result, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE BELOW CONTAINS DIFFERENT GRID SEARCHS I WAS TESTING OUT\n",
    "# KEEPING THIS IN THE NOTEBOOK FOR FUTURE REFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for activation method\n",
    "# def create_base_model(activation='relu'):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='tanh'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=3, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create activation model\n",
    "# model = KerasClassifier(build_fn=create_base_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the activation grid search parameters\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "\n",
    "\n",
    "# # Assign the activation grid search parameters, fit, and run the model\n",
    "# param_grid = dict(activation=activation)\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "# grid_result = activation_grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the score and best params for the activation model\n",
    "# print(\"Best: %f using %s\" % (activation_grid_result.best_score_, activation_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Training Data Score: {activation_grid_result.score(X_train_scaled, y_train_categorical)}\")\n",
    "# print(f\"Testing Data Score: {activation_grid_result.score(X_test_scaled, y_test_categorical)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for the model\n",
    "# def create_model(activation='adam', dropout_rate=0.0):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='tanh'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=3, activation='softmax'))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create model\n",
    "# model = KerasClassifier(build_fn=create_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the activation and dropout rate grid search parameters\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "# # Assign the grid search parameters, fit, and run the model\n",
    "# param_grid = dict(activation=activation, dropout_rate=dropout_rate)\n",
    "# fit_grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "# grid_result = fit_grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the score and best params for the activation model\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for optimizer model\n",
    "# def create_optimizer_model(optimizer='adam'):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid', input_dim=5))\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid'))\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid'))\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid'))\n",
    "#     model.add(Dense(units=3, activation='hard_sigmoid'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create optimizer model\n",
    "# optimizer_model = KerasClassifier(build_fn=create_optimizer_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the optimizer grid search parameters\n",
    "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "\n",
    "# # Assign the optimizer grid search parameters, fit, and run the model\n",
    "# optimizer_param_grid = dict(optimizer=optimizer)\n",
    "# optimizer_grid = GridSearchCV(estimator=optimizer_model, param_grid=optimizer_param_grid, n_jobs=-1)\n",
    "# optimizer_grid_result = optimizer_grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the score and best params for the optimizer model\n",
    "# print(\"Best: %f using %s\" % (optimizer_grid_result.best_score_, optimizer_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for dropout model\n",
    "# def create_dropout_model(dropout_rate=0.0):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='tanh'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=3, activation='softmax'))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy']) \n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create the dropout model\n",
    "# dropout_model = KerasClassifier(build_fn=create_dropout_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the dropout grid search parameters\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "# # Assign the dropout grid search parameters, fit, and run the model\n",
    "# dropout_param_grid = dict(dropout_rate=dropout_rate)\n",
    "# dropout_grid = GridSearchCV(estimator=dropout_model, param_grid=dropout_param_grid, n_jobs=-1)\n",
    "# dropout_grid_result = dropout_grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the score and best params for the dropout model\n",
    "# print(\"Best: %f using %s\" % (dropout_grid_result.best_score_, dropout_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Training Data Score: {model2.score(X_train_scaled, y_train)}\")\n",
    "# print(f\"Testing Data Score: {model2.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
