{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import initial dependencies\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CSVs to DFs\n",
    "features = \"../../prediction_modeling/output/reduced_wine_features.csv\"\n",
    "targets = \"../../prediction_modeling/output/reduced_wine_targets.csv\"\n",
    "\n",
    "features_df = pd.read_csv(features)\n",
    "targets_df =pd.read_csv(targets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>white</th>\n",
       "      <th>country_Argentina</th>\n",
       "      <th>country_Australia</th>\n",
       "      <th>country_Chile</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Portugal</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>country_US</th>\n",
       "      <th>flavor_categories_taste_notes_light, fruity</th>\n",
       "      <th>flavor_categories_taste_notes_medium bodied, balanced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  white  country_Argentina  country_Australia  country_Chile  \\\n",
       "0   15.0    0.0                  0                  0              0   \n",
       "1   65.0    0.0                  0                  0              0   \n",
       "2   19.0    0.0                  0                  0              0   \n",
       "3   34.0    0.0                  0                  0              0   \n",
       "4   30.0    0.0                  1                  0              0   \n",
       "\n",
       "   country_Germany  country_Portugal  country_Spain  country_US  \\\n",
       "0                0                 1              0           0   \n",
       "1                0                 0              0           1   \n",
       "2                0                 0              0           1   \n",
       "3                0                 0              0           1   \n",
       "4                0                 0              0           0   \n",
       "\n",
       "   flavor_categories_taste_notes_light, fruity  \\\n",
       "0                                            1   \n",
       "1                                            0   \n",
       "2                                            1   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "   flavor_categories_taste_notes_medium bodied, balanced  \n",
       "0                                                  0      \n",
       "1                                                  1      \n",
       "2                                                  0      \n",
       "3                                                  1      \n",
       "4                                                  1      "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature DF head\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109662, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature DF shape\n",
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   points\n",
       "0      87\n",
       "1      87\n",
       "2      87\n",
       "3      87\n",
       "4      87"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check targets DF\n",
    "targets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "points    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Dtypes\n",
    "targets_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109662, 11) (109662, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check feature and target DF shape\n",
    "print(features_df.shape, targets_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.  0.  0. ...  0.  1.  0.]\n",
      " [65.  0.  0. ...  1.  0.  1.]\n",
      " [19.  0.  0. ...  1.  1.  0.]\n",
      " ...\n",
      " [70.  0.  0. ...  0.  0.  0.]\n",
      " [25.  0.  0. ...  1.  0.  0.]\n",
      " [38.  0.  0. ...  0.  0.  0.]] [[87]\n",
      " [87]\n",
      " [87]\n",
      " ...\n",
      " [90]\n",
      " [90]\n",
      " [91]]\n"
     ]
    }
   ],
   "source": [
    "# Assign the features and target to X and y abd check assignments\n",
    "raw_feature_data = features_df.values\n",
    "raw_target_data = targets_df.values\n",
    "X = raw_feature_data[:, 0:12]\n",
    "y = raw_target_data.reshape(-1,1)\n",
    "\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT, NORMALIZE, AND ENCODE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and test sets for the features and target\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using the MinMax scaler since we know their values\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "y_scaler = MinMaxScaler().fit(y_train)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPERAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sequential and dense modules fo build my NN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN XGB REGRESSOR ON SCALED DATA AND INSPECT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Regressor...\n",
      "parameters:\n",
      "{'batch_size': [10, 20, 40, 60, 80, 100],\n",
      " 'learning_rate': [0.01, 0.001, 0.0001],\n",
      " 'max_depth': [3, 5, 7, 9],\n",
      " 'n_estimators': [200, 300, 500]}\n",
      "[04:51:40] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Best score: 0.415\n",
      "Best parameters set:\n",
      "\tbatch_size: 10\n",
      "\tlearning_rate: 0.01\n",
      "\tmax_depth: 7\n",
      "\tn_estimators: 500\n",
      "Select Done..., Time Cost: 8505.\n"
     ]
    }
   ],
   "source": [
    "print('XGB Regressor...')\n",
    "\n",
    "# Import dependencies\n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "# Create start time and model for XGB Regressor\n",
    "start_time  = datetime.now()\n",
    "xgb_reg = XGBRegressor() \n",
    "\n",
    "# Create parameter dictionary and insert into the grid search constructor\n",
    "parameters = {'n_estimators': [200, 300, 500], 'max_depth':[3,5,7,9], \\\n",
    "              'learning_rate':[.01, .001, .0001], 'batch_size':[10, 20, 40, 60, 80, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_reg, param_grid=parameters, cv=10, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Print out parameters\n",
    "print(\"parameters:\")\n",
    "pprint.pprint(parameters)\n",
    "\n",
    "\n",
    "# Fit model\n",
    "grid_search.fit(X_train_scaled, y_train_scaled.ravel())\n",
    "\n",
    "\n",
    "# Print best sore, best parameters\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters=grid_search.best_estimator_.get_params()\n",
    "\n",
    "\n",
    "# Loop through params and get keys + print time cost\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "end_time = datetime.now()\n",
    "print(f'Select Done..., Time Cost: {((end_time - start_time).seconds)}.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.013813830501431295\n",
      "R-squared (R2): 0.41036356954076403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Use our model to predict a value\n",
    "predicted = grid_search.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse = mean_squared_error(y_test_scaled, predicted)\n",
    "r2 = r2_score(y_test_scaled, predicted)\n",
    "\n",
    "# Print scores\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42429772, 0.30697387, 0.33906835, 0.39895833, 0.56125796,\n",
       "       0.399701  , 0.47776294, 0.5480776 , 0.40939444, 0.45089942],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of predictions and check\n",
    "predicted_list = grid_search.predict(X_test_scaled)\n",
    "\n",
    "predicted_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55],\n",
       "       [0.45],\n",
       "       [0.45],\n",
       "       [0.4 ],\n",
       "       [0.4 ],\n",
       "       [0.65],\n",
       "       [0.4 ],\n",
       "       [0.6 ],\n",
       "       [0.25],\n",
       "       [0.35]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of actual values and check\n",
    "actual_list = y_test_scaled\n",
    "\n",
    "actual_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_Predictions</th>\n",
       "      <th>Actual_Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.424298</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.306974</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.339068</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.398958</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.561258</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.399701</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.477763</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.548078</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.409394</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.450899</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XGB_Predictions  Actual_Points\n",
       "0         0.424298           0.55\n",
       "1         0.306974           0.45\n",
       "2         0.339068           0.45\n",
       "3         0.398958           0.40\n",
       "4         0.561258           0.40\n",
       "5         0.399701           0.65\n",
       "6         0.477763           0.40\n",
       "7         0.548078           0.60\n",
       "8         0.409394           0.25\n",
       "9         0.450899           0.35"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DF to further compare predictions with actual points\n",
    "prediction_comparrisons_df = pd.DataFrame({'XGB_Predictions':predicted_list,\n",
    "                                           'Actual_Points':actual_list.ravel()\n",
    "                                          })\n",
    "\n",
    "prediction_comparrisons_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export prediction comparrisons\n",
    "prediction_comparrisons_df.to_csv(r'C:\\Users\\howar\\Desktop\\Data Science Boot Camp\\Group_Project_3\\prediction_modeling\\output\\predictions_vs_acttual.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models\\\\XGB_Regressor_scaled.sav']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the tuned model for future use\n",
    "import joblib\n",
    "filename = 'saved_models\\XGB_Regressor_scaled.sav'\n",
    "joblib.dump(grid_search, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run XGB Regressor with unscalled data and recommended parameters from the previous test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Model...\n",
      "parameters:\n",
      "{'batch_size': [10],\n",
      " 'learning_rate': [0.01],\n",
      " 'max_depth': [7],\n",
      " 'n_estimators': [850]}\n",
      "[07:38:27] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Best score: 0.415\n",
      "Best parameters set:\n",
      "\tbatch_size: 10\n",
      "\tlearning_rate: 0.01\n",
      "\tmax_depth: 7\n",
      "\tn_estimators: 850\n",
      "Select Done..., Time Cost: 153.\n"
     ]
    }
   ],
   "source": [
    "print('Select Model...')\n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "start_time_2  = datetime.now()\n",
    "xgb_reg_2 = XGBRegressor() \n",
    "\n",
    "\n",
    "parameters_reg_2 = {'n_estimators': [850], 'max_depth':[7], \\\n",
    "              'learning_rate':[.01], 'batch_size':[10]}\n",
    "\n",
    "grid_search_2 = GridSearchCV(estimator=xgb_reg_2, param_grid=parameters_reg_2, cv=10, n_jobs=-1)\n",
    "\n",
    "\n",
    "print(\"parameters:\")\n",
    "pprint.pprint(parameters_reg_2)\n",
    "\n",
    "\n",
    "grid_2 = grid_search_2.fit(X_train, y_train.ravel())\n",
    "\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_2.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters_2=grid_2.best_estimator_.get_params()\n",
    "\n",
    "\n",
    "for param_name in sorted(parameters_reg_2.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters_2[param_name]))\n",
    "end_time_2 = datetime.now()\n",
    "print(f'Select Done..., Time Cost: {((end_time_2 - start_time_2).seconds)}.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 5.517620949521715\n",
      "R-squared (R2): 0.4112077890042899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Use our model to predict a value\n",
    "predicted_2 = grid_2.predict(X_test)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse_2 = mean_squared_error(y_test, predicted_2)\n",
    "r2_2 = r2_score(y_test, predicted_2)\n",
    "\n",
    "# Print scores\n",
    "print(f\"Mean Squared Error (MSE): {mse_2}\")\n",
    "print(f\"R-squared (R2): {r2_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of predictions and check\n",
    "predicted_list_unscaled = grid_2.predict(X_test)\n",
    "\n",
    "predicted_list_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91],\n",
       "       [89],\n",
       "       [89],\n",
       "       ...,\n",
       "       [91],\n",
       "       [96],\n",
       "       [90]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of actual values and check\n",
    "actual_list_unscaled = y_test\n",
    "\n",
    "actual_list_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_Predictions (unscaled)</th>\n",
       "      <th>Actual_Points (unscaled)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.490555</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.018265</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.880157</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.046768</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.225143</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88.015190</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89.570747</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90.953506</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>88.181931</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>88.933014</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.803322</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>90.840034</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>86.095047</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90.085144</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>86.080811</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>86.886673</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>89.833130</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90.153130</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91.915848</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>87.967140</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>90.224358</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>88.802513</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>89.523293</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>91.661644</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>89.361000</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>89.122414</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>88.844162</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>87.122345</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>87.361786</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>88.844162</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>91.793114</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>84.877502</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>88.046768</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>88.329163</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>91.905602</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>91.524864</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>87.801758</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>90.141830</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>89.168655</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>90.500465</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    XGB_Predictions (unscaled)  Actual_Points (unscaled)\n",
       "0                    88.490555                        91\n",
       "1                    86.018265                        89\n",
       "2                    86.880157                        89\n",
       "3                    88.046768                        88\n",
       "4                    91.225143                        88\n",
       "5                    88.015190                        93\n",
       "6                    89.570747                        88\n",
       "7                    90.953506                        92\n",
       "8                    88.181931                        85\n",
       "9                    88.933014                        87\n",
       "10                   86.803322                        89\n",
       "11                   90.840034                        86\n",
       "12                   86.095047                        89\n",
       "13                   90.085144                        87\n",
       "14                   86.080811                        90\n",
       "15                   86.886673                        86\n",
       "16                   89.833130                        88\n",
       "17                   90.153130                        87\n",
       "18                   91.915848                        94\n",
       "19                   87.967140                        88\n",
       "20                   90.224358                        93\n",
       "21                   88.802513                        90\n",
       "22                   89.523293                        89\n",
       "23                   91.661644                        94\n",
       "24                   89.361000                        88\n",
       "25                   89.122414                        90\n",
       "26                   88.844162                        91\n",
       "27                   87.122345                        88\n",
       "28                   87.361786                        90\n",
       "29                   88.844162                        91\n",
       "30                   91.793114                        91\n",
       "31                   84.877502                        83\n",
       "32                   88.046768                        93\n",
       "33                   88.329163                        91\n",
       "34                   91.905602                        93\n",
       "35                   91.524864                        90\n",
       "36                   87.801758                        84\n",
       "37                   90.141830                        88\n",
       "38                   89.168655                        90\n",
       "39                   90.500465                        91"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DF for unscaled test to further compare predictions with actual points\n",
    "prediction_comparrisons_unscaled_df = pd.DataFrame({'XGB_Predictions (unscaled)' : predicted_list_unscaled,\n",
    "                                           'Actual_Points (unscaled)' : actual_list_unscaled.ravel()\n",
    "                                          })\n",
    "\n",
    "prediction_comparrisons_unscaled_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export unscaled results\n",
    "prediction_comparrisons_unscaled_df.to_csv(r'C:\\Users\\howar\\Desktop\\Data Science Boot Camp\\Group_Project_3\\prediction_modeling\\output\\predictions_vs_actual_unscaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models\\\\XGB_Regressor_unscaled_(BEST).sav']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the tuned model for future use\n",
    "import joblib\n",
    "filename = 'saved_models\\XGB_Regressor_unscaled_(BEST).sav'\n",
    "joblib.dump(grid_2, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEE WHAT A CLASSIFIER DOES WITH THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 26 candidates, totalling 52 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [25, 10, 4, 2, 1.0, 0.8, 0.5, 0.3, 0.2, 0.1,\n",
       "                                   0.05, 0.02, 0.01],\n",
       "                         'normalize': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Test other models for comparrison\n",
    "# NOTE, THESE ARE CLASSIFICATION MODELS I AM TRYIN OUT JUST TO SEE HOW IT PERFORMS ON THE DATA\n",
    "params_clf={'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01],\n",
    "            'normalize': [True, False]}\n",
    "\n",
    "\n",
    "# Creat, fit, and test model\n",
    "rdg_clf = Ridge()\n",
    "clf_grid = GridSearchCV(rdg_clf, params_clf, cv=2, verbose = 1, scoring = 'neg_mean_squared_error')\n",
    "clf_grid.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.018771 using {'alpha': 0.02, 'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "# Print the score and best params for the activation model\n",
    "print(\"Best: %f using %s\" % (clf_grid.best_score_, clf_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.018561234926338842\n",
      "R-squared (R2): 0.20772299140721662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Use our model to predict a value\n",
    "predicted_3 = clf_grid.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse_3 = mean_squared_error(y_test_scaled, predicted_3)\n",
    "r2_3 = r2_score(y_test_scaled, predicted_3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Squared Error (MSE): {mse_3}\")\n",
    "print(f\"R-squared (R2): {r2_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[149.36928326],\n",
       "       [ 60.91139232],\n",
       "       [112.09340453],\n",
       "       ...,\n",
       "       [107.52408247],\n",
       "       [382.10829152],\n",
       "       [ 84.17701498]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of predictions and check\n",
    "predicted_list_clf = clf_grid.predict(X_test)\n",
    "\n",
    "predicted_list_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91],\n",
       "       [89],\n",
       "       [89],\n",
       "       ...,\n",
       "       [91],\n",
       "       [96],\n",
       "       [90]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of actual values and check\n",
    "actual_list_clf = y_test\n",
    "\n",
    "actual_list_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models\\\\Ridge_Classifier.sav']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the tuned model for future use\n",
    "import joblib\n",
    "filename = 'saved_models\\Ridge_Classifier.sav'\n",
    "joblib.dump(clf_grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING OUT OTHER MODEL EXAMPLES I FOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=2, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=2, min_samples_split=4,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Try some different model examples I found when doing my research...\n",
    "def cross_validate_best_known():\n",
    "    '''\n",
    "        import and clean the wine data, then do a corss validation on each of the three models we are\n",
    "        training here. A RandomForest, a GradientBoost, and an AdaBoost backed by a DecisionTree. Print\n",
    "        the scores.\n",
    "\n",
    "        The parameters we're using here are the \"best\" that we've found so far using a grid search.\n",
    "    '''\n",
    "\n",
    "rf = RandomForestRegressor(max_features=2, min_samples_split=4, n_estimators=50, min_samples_leaf=2)\n",
    "gb = GradientBoostingRegressor(loss='quantile', learning_rate=0.0001, n_estimators=50, max_features='log2', min_samples_split=2, max_depth=1)\n",
    "ada_tree_backing = DecisionTreeRegressor(max_features='sqrt', splitter='random', min_samples_split=4, max_depth=3)\n",
    "ab = AdaBoostRegressor(ada_tree_backing, learning_rate=0.0001, loss='square', n_estimators=100000)\n",
    "\n",
    "# Fit the data to the Random Forest Regressor\n",
    "rf.fit(X_train_scaled, y_train_scaled.ravel())\n",
    "\n",
    "\n",
    "# validate.cross_v_scores([rf, gb, ab], X_train_scaled, y_train_scaled)\n",
    "# # RandomForestRegressor -- RMLSE: -0.596797712098, R2: 0.0272065373946\n",
    "# GradientBoostingRegressor -- RMLSE: -0.996134592541, R2: -2.37202164829\n",
    "# AdaBoostRegressor -- RMLSE: -0.706385708459, R2: -0.103966980393 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our model to predict a value\n",
    "predicted_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse_rf = mean_squared_error(y_test_scaled, predicted_rf)\n",
    "r2_rf = r2_score(y_test_scaled, predicted_rf)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Squared Error (MSE): {mse_rf}\")\n",
    "print(f\"R-squared (R2): {r2_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of predictions and check\n",
    "predicted_list_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "predicted_list_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of actual values and check\n",
    "actual_list_rf = y_test_scaled\n",
    "\n",
    "actual_list_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tuned model for future use\n",
    "import joblib\n",
    "filename = 'saved_models\\RF_Regr.sav'\n",
    "joblib.dump(rf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.0001, loss='quantile', max_depth=1,\n",
       "                          max_features='log2', max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the data to the Gradient Boosting Regressor\n",
    "gb.fit(X_train_scaled, y_train_scaled.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.07489888217478236\n",
      "R-squared (R2): -2.1970212408751997\n"
     ]
    }
   ],
   "source": [
    "# Use our model to predict a value\n",
    "predicted_4 = gb.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse_4 = mean_squared_error(y_test_scaled, predicted_4)\n",
    "r2_4 = r2_score(y_test_scaled, predicted_4)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Squared Error (MSE): {mse_4}\")\n",
    "print(f\"R-squared (R2): {r2_4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of predictions and check\n",
    "predicted_list_gb = gb.predict(X_test_scaled)\n",
    "\n",
    "predicted_list_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of actual values and check\n",
    "actual_list_gb = y_test_scaled\n",
    "\n",
    "actual_list_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tuned model for future use\n",
    "import joblib\n",
    "filename = 'saved_models\\GB_Regr.sav'\n",
    "joblib.dump(gb, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features='sqrt',\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='random')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the data to the ADA Tree Backing Regressor\n",
    "ada_tree_backing.fit(X_train_scaled, y_train_scaled.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.022553979373154898\n",
      "R-squared (R2): 0.037294696148155615\n"
     ]
    }
   ],
   "source": [
    "# Use our model to predict a value\n",
    "predicted_5 = ada_tree_backing.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse_5 = mean_squared_error(y_test_scaled, predicted_5)\n",
    "r2_5 = r2_score(y_test_scaled, predicted_5)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Mean Squared Error (MSE): {mse_5}\")\n",
    "print(f\"R-squared (R2): {r2_5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of predictions and check\n",
    "predicted_list_ada_tree_backing = ada_tree_backing.predict(X_test_scaled)\n",
    "\n",
    "predicted_list_ada_tree_backing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of actual values and check\n",
    "actual_list_ada_tree_backing = y_test_scaled\n",
    "\n",
    "actual_list_ada_tree_backing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tuned model for future use\n",
    "import joblib\n",
    "filename = 'saved_models\\ADA_Tree_Backing.sav'\n",
    "joblib.dump(ada_tree_backing, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data to the ADA Boosting Regressor\n",
    "ab.fit(X_train_scaled, y_train_scaled.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our model to predict a value\n",
    "predicted_6 = ab.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse_6 = mean_squared_error(y_test_scaled, predicted_6)\n",
    "r2_6 = r2_score(y_test_scaled, predicted_6)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Mean Squared Error (MSE): {mse_6}\")\n",
    "print(f\"R-squared (R2): {r2_6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of predictions and check\n",
    "predicted_list_ab = ab.predict(X_test_scaled)\n",
    "\n",
    "predicted_list_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of actual values and check\n",
    "actual_list_ab = y_test_scaled\n",
    "\n",
    "actual_list_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tuned model for future use\n",
    "import joblib\n",
    "filename = 'saved_models\\AB_Reg.sav'\n",
    "joblib.dump(ab, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING MY BUILD OF THE KERAS REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base Keras classifier wrapper for activation method\n",
    "def create_base_model(activation='relu'):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1000, activation='relu', input_dim=11))\n",
    "    model.add(Dense(units=1000, activation='relu'))\n",
    "    model.add(Dense(units=1000, activation='relu'))\n",
    "    model.add(Dense(units=1000, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Create activation model\n",
    "keras_model = KerasRegressor(build_fn=create_base_model, epochs=20, batch_size=88)\n",
    "\n",
    "\n",
    "# Define the activation grid search parameters\n",
    "batch_size = [10, 32, 64, 88, 100, 150]\n",
    "\n",
    "\n",
    "# Assign the activation grid search parameters, fit, and run the model\n",
    "keras_param_grid = dict(batch_size=batch_size)\n",
    "keras_grid = GridSearchCV(estimator=keras_model, param_grid=keras_param_grid, n_jobs=-1)\n",
    "keras_grid_result = keras_grid.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the score and best params for the activation model\n",
    "print(\"Best: %f using %s\" % (keras_grid_result.best_score_, activation_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {keras_grid_result.score(X_train_scaled, y_train_scaled)}\")\n",
    "print(f\"Testing Data Score: {keras_grid_result.score(X_train_scaled, y_train_scaled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our model to predict a value\n",
    "predicted_7 = keras_grid_result.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse_7 = mean_squared_error(y_test_scaled, predicted_7)\n",
    "r2_7 = r2_score(y_test_scaled, predicted_7)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Mean Squared Error (MSE): {mse_7}\")\n",
    "print(f\"R-squared (R2): {r2_7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of predictions and check\n",
    "predicted_list_keras = keras_grid_result.predict(X_test_scaled)\n",
    "\n",
    "predicted_list_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of actual values and check\n",
    "actual_list_keras = y_test_scaled\n",
    "\n",
    "actual_list_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tuned model for future use\n",
    "import joblib\n",
    "filename = 'saved_models\\Keras_Reg_NN.sav'\n",
    "joblib.dump(keras_grid_result, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for the model\n",
    "# def create_model(activation='adam', dropout_rate=0.0):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='tanh'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=3, activation='softmax'))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create model\n",
    "# model = KerasClassifier(build_fn=create_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the activation and dropout rate grid search parameters\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "# # Assign the grid search parameters, fit, and run the model\n",
    "# param_grid = dict(activation=activation, dropout_rate=dropout_rate)\n",
    "# fit_grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "# grid_result = fit_grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the score and best params for the activation model\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for optimizer model\n",
    "# def create_optimizer_model(optimizer='adam'):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid', input_dim=5))\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid'))\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid'))\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid'))\n",
    "#     model.add(Dense(units=3, activation='hard_sigmoid'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create optimizer model\n",
    "# optimizer_model = KerasClassifier(build_fn=create_optimizer_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the optimizer grid search parameters\n",
    "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "\n",
    "# # Assign the optimizer grid search parameters, fit, and run the model\n",
    "# optimizer_param_grid = dict(optimizer=optimizer)\n",
    "# optimizer_grid = GridSearchCV(estimator=optimizer_model, param_grid=optimizer_param_grid, n_jobs=-1)\n",
    "# optimizer_grid_result = optimizer_grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the score and best params for the optimizer model\n",
    "# print(\"Best: %f using %s\" % (optimizer_grid_result.best_score_, optimizer_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for dropout model\n",
    "# def create_dropout_model(dropout_rate=0.0):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='tanh'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=3, activation='softmax'))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy']) \n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create the dropout model\n",
    "# dropout_model = KerasClassifier(build_fn=create_dropout_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the dropout grid search parameters\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "# # Assign the dropout grid search parameters, fit, and run the model\n",
    "# dropout_param_grid = dict(dropout_rate=dropout_rate)\n",
    "# dropout_grid = GridSearchCV(estimator=dropout_model, param_grid=dropout_param_grid, n_jobs=-1)\n",
    "# dropout_grid_result = dropout_grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the score and best params for the dropout model\n",
    "# print(\"Best: %f using %s\" % (dropout_grid_result.best_score_, dropout_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Training Data Score: {model2.score(X_train_scaled, y_train)}\")\n",
    "# print(f\"Testing Data Score: {model2.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
